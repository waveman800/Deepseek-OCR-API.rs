# deepseek-ocr.rs ğŸš€

Rust å®ç°çš„ DeepSeek-OCR æ¨ç†æ ˆï¼Œæä¾›å¿«é€Ÿ CLI ä¸ OpenAI å…¼å®¹çš„ HTTP Serverï¼Œç»Ÿä¸€æ‰“åŒ…æ¨¡å‹åŠ è½½ã€è§†è§‰è¾“å…¥é¢„å¤„ç†ã€æç¤ºè¯å·¥å…·ä¸æœåŠ¡ç«¯èƒ½åŠ›ï¼Œæ–¹ä¾¿åœ¨æœ¬åœ° CPUã€Apple Metal æˆ– NVIDIA CUDA GPU ä¸Šæ„å»ºæ–‡æ¡£ç†è§£å·¥ä½œæµã€‚

> è‹±æ–‡æ–‡æ¡£è¯·å‚è§ [README.md](README.md)ã€‚  

> æƒ³ç›´æ¥ä¸‹è½½å¯æ‰§è¡Œæ–‡ä»¶ï¼Ÿè®¿é—® [Github Actions](https://github.com/TimmyOVO/deepseek-ocr.rs/actions/workflows/build-binaries.yml)ï¼Œä¸‹è½½æœ€æ–°ä¸€æ¬¡æˆåŠŸè¿è¡Œç”Ÿæˆçš„ macOSï¼ˆå« Metalï¼‰æˆ– Windows å‹ç¼©åŒ…ã€‚

## æ¨¡å‹é€‰æ‹©æŒ‡å— ğŸ”¬

| æ¨¡å‹ | å†…å­˜å ç”¨* | æœ€ä½³ç¡¬ä»¶ | é€‚ç”¨åœºæ™¯ |
| --- | --- | --- | --- |
| **DeepSeekâ€‘OCR** | **â‰ˆ6.3â€¯GB** FP16 æƒé‡ï¼Œå«æ¿€æ´»/ç¼“å­˜çº¦ **13â€¯GB**ï¼ˆ512 tokenï¼‰ | Apple Silicon + Metalã€24â€¯GB VRAM NVIDIAã€32â€¯GB+ RAM æ¡Œé¢ | è¿½æ±‚æœ€é«˜å‡†ç¡®ç‡ã€å¤šè§†è§’æ–‡æ¡£ã€å¯¹å»¶è¿Ÿä¸æ•æ„Ÿã€‚SAM+CLIP è§†è§‰ + DeepSeekâ€‘V2 MoEï¼ˆ3â€¯B å‚æ•°ï¼Œå• token æ¿€æ´» â‰ˆ570â€¯Mï¼‰ã€‚ |
| **PaddleOCRâ€‘VL** | **â‰ˆ4.7â€¯GB** FP16 æƒé‡ï¼Œå«æ¿€æ´»/ç¼“å­˜çº¦ **9â€¯GB** | 16â€¯GB ç¬”ç”µã€CPU-only èŠ‚ç‚¹ã€ä¸­ç«¯ GPU | æ›´å¿«å†·å¯åŠ¨ï¼Œdense Ernie decoderï¼ˆ0.9â€¯Bï¼‰+ SigLIP è§†è§‰ï¼Œé€‚åˆæ‰¹é‡ä½œä¸šä¸è½»é‡éƒ¨ç½²ã€‚ |

\*é»˜è®¤ FP16 safetensors å®¹é‡ï¼›å®é™…èµ„æºä¸åºåˆ—é•¿åº¦ã€æ˜¯å¦å¯ç”¨ KV Cache ç›¸å…³ã€‚

é€‰æ‹©å»ºè®®ï¼š

- **æœ‰ 16â€“24â€¯GB ä»¥ä¸Š VRAM / RAMã€è¿½æ±‚æè‡´è´¨é‡ï¼Ÿ** é€‰ **DeepSeekâ€‘OCR**ï¼ŒSAM+CLIP å…¨å±€+å±€éƒ¨è§†é‡ã€DeepSeekâ€‘V2 MoE è§£ç èƒ½åœ¨å¤æ‚ç‰ˆå¼ä¸­ä¿æŒæ›´é«˜è¿˜åŸåº¦ï¼Œä½†ä»£ä»·æ˜¯æ›´å¤§çš„æ˜¾å­˜å’Œæ›´é«˜å»¶è¿Ÿã€‚
- **ç¡¬ä»¶é¢„ç®—æœ‰é™æˆ–éœ€è¦ä½å»¶è¿Ÿ / é«˜ååï¼Ÿ** é€‰ **PaddleOCRâ€‘VL**ï¼ŒSigLIP + dense Ernieï¼ˆ18 å±‚ã€hidden 1024ï¼‰åœ¨ 10â€¯GB ä»¥å†…å³å¯è¿è¡Œï¼ŒCPU æ¨¡å¼ä¹Ÿæ›´æ˜“éƒ¨ç½²ã€‚

## ä¸ºä»€ä¹ˆé€‰æ‹© Rustï¼ŸğŸ’¡

å®˜æ–¹ DeepSeek-OCR ä¾èµ– Python + Transformersï¼Œéƒ¨ç½²ä½“ç§¯å¤§ã€ä¾èµ–å¤šï¼ŒåµŒå…¥åŸç”Ÿç³»ç»Ÿæˆæœ¬é«˜ã€‚Rust é‡å†™åçš„ä¼˜åŠ¿ï¼š

- æ— éœ€ Python è¿è¡Œæ—¶æˆ– condaï¼Œäº§ç‰©æ›´å°ã€æ›´æ˜“åµŒå…¥ã€‚
- å†…å­˜å®‰å…¨ã€çº¿ç¨‹å‹å¥½ï¼Œå¯ç›´æ¥èå…¥ç°æœ‰ Rust æœåŠ¡ã€‚
- CLI ä¸ Server å…±ç”¨ä¸€å¥—æ ¸å¿ƒé€»è¾‘ï¼Œé¿å…é‡å¤ç»´æŠ¤ã€‚
- ä¾æ—§å…¼å®¹ OpenAI å®¢æˆ·ç«¯ï¼ŒåŒæ—¶èšç„¦å•è½® OCR åœºæ™¯ç¡®ä¿è¾“å‡ºç¨³å®šã€‚

## æŠ€æœ¯æ ˆ âš™ï¸

- **Candle**ï¼šRust æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œæ”¯æŒ Metal/CUDAï¼ˆalphaï¼‰ ä¸ FlashAttentionã€‚
- **Rocket**ï¼šå¼‚æ­¥ HTTP æ¡†æ¶ï¼Œæä¾› `/v1/responses`ã€`/v1/chat/completions` ç­‰ OpenAI å…¼å®¹è·¯ç”±ã€‚
- **tokenizers**ï¼šä¸Šæ¸¸æ¨¡å‹æä¾›çš„ Tokenizerï¼Œé€šè¿‡ `crates/assets` åœ¨ Hugging Face / ModelScope é•œåƒé—´ç¼“å­˜ä¸æ ¡éªŒã€‚
- **çº¯ Rust è§†è§‰/Prompt ç®¡çº¿**ï¼šCLI ä¸ Server å¤ç”¨ï¼Œå‡å°‘é‡å¤é€»è¾‘ã€‚

## ç›¸æ¯” Python å®ç°çš„ä¼˜åŠ¿ ğŸ¥·

- Apple Silicon å†·å¯åŠ¨æ›´å¿«ã€å†…å­˜å ç”¨æ›´ä½ï¼Œä¸”æä¾›åŸç”ŸäºŒè¿›åˆ¶åˆ†å‘ã€‚
- èµ„äº§ä¸‹è½½/æ ¡éªŒç”± Rust crate ç»Ÿä¸€æ‰˜ç®¡ï¼Œå¯åœ¨ Hugging Face ä¸ ModelScope ä¹‹é—´è‡ªåŠ¨åˆ‡æ¢ã€‚
- è‡ªåŠ¨æŠ˜å å¤šè½®ä¼šè¯ï¼Œä»…ä¿ç•™æœ€è¿‘ä¸€æ¬¡ user æç¤ºï¼Œç¡®ä¿ OCR åœºæ™¯ç¨³å®šã€‚
- ä¸ Open WebUI ç­‰ OpenAI å®¢æˆ·ç«¯â€œå³æ’å³ç”¨â€ï¼Œæ— éœ€é¢å¤–é€‚é…å±‚ã€‚

## é¡¹ç›®äº®ç‚¹ âœ¨

- **ä¸€å¥—ä»£ç ï¼Œä¸¤ç§å…¥å£**ï¼šæ‰¹å¤„ç†å‹å¥½çš„ CLI ä¸å…¼å®¹ `/v1/responses`ã€`/v1/chat/completions` çš„ Rocket Serverã€‚
- **å¼€ç®±å³ç”¨**ï¼šé¦–æ¬¡è¿è¡Œè‡ªåŠ¨ä» Hugging Face æˆ– ModelScopeï¼ˆå–å†³äºå®æ—¶å»¶è¿Ÿï¼‰æ‹‰å–é…ç½®ã€Tokenizer ä¸æƒé‡ã€‚
- **Apple Silicon å‹å¥½**ï¼šMetal + FP16 åŠ é€Ÿè®©ç¬”è®°æœ¬ä¹Ÿèƒ½å®æ—¶ OCRã€‚
- **NVIDIA GPUï¼ˆÎ± æµ‹è¯•ï¼‰**ï¼šæ„å»ºæ—¶é™„åŠ  `--features cuda` å¹¶ä»¥ `--device cuda --dtype f16` è¿è¡Œï¼Œå¯åœ¨ Linux/Windows ä¸Šå°é²œ CUDA åŠ é€Ÿã€‚
- **Intel MKLï¼ˆé¢„è§ˆï¼‰**ï¼šå®‰è£… Intel oneMKL åï¼Œæ„å»ºæ—¶é™„åŠ  `--features mkl` ä»¥æå‡ x86 CPU ä¸Šçš„çŸ©é˜µè¿ç®—é€Ÿåº¦ã€‚
- **OpenAI å®¢æˆ·ç«¯å³æ’å³ç”¨**ï¼šServer ç«¯è‡ªåŠ¨æŠ˜å å¤šè½®å¯¹è¯ï¼Œåªä¿ç•™æœ€æ–° user æŒ‡ä»¤ï¼Œé¿å… OCR æ¨¡å‹è¢«å¤šè½®ä¸Šä¸‹æ–‡å¹²æ‰°ã€‚

## å¿«é€Ÿä¸Šæ‰‹ ğŸ

### ç¯å¢ƒè¦æ±‚

- Rust 1.78+ï¼ˆæ”¯æŒ 2024 Editionï¼‰
- Git
- å¯é€‰ï¼šmacOS 13+ çš„ Apple Siliconï¼ˆç”¨äº Metalï¼‰
- å¯é€‰ï¼šLinux/Windows çš„ NVIDIA GPUï¼ˆéœ€ CUDA 12.2+ å·¥å…·é“¾ä¸é©±åŠ¨ï¼Œå½“å‰ä¸ºalphaé˜¶æ®µï¼‰
- å¯é€‰ï¼šx86 å¹³å°å®‰è£… Intel oneMKLï¼ˆé¢„è§ˆï¼‰ï¼Œç”¨äºæå‡ CPU æ¨ç†æ€§èƒ½
- æ¨èï¼šé…ç½® `HF_TOKEN` è®¿é—® Hugging Face `deepseek-ai/DeepSeek-OCR`ï¼ˆè‹¥è¯¥æºä¸å¯ç”¨ä¼šè‡ªåŠ¨åˆ‡æ¢ ModelScopeï¼‰

### å…‹éš†ä»“åº“

```bash
git clone https://github.com/TimmyOVO/deepseek-ocr.rs.git
cd deepseek-ocr.rs
cargo fetch
```

### æ¨¡å‹èµ„æº

ç¬¬ä¸€æ¬¡è¿è¡Œ CLI æˆ– Server ä¼šæŠŠé…ç½®ã€tokenizer åŠ ~6.3GB çš„ `model-00001-of-000001.safetensors` ä¸‹è½½åˆ° `DeepSeek-OCR/`ã€‚ä¹Ÿå¯ä»¥æ‰‹åŠ¨è§¦å‘ï¼š

```bash
cargo run -p deepseek-ocr-cli --release -- --help # dev profile ææ…¢ï¼Œå»ºè®®å§‹ç»ˆåŠ  --release
```

è‹¥è‡ªå®šä¹‰ç¼“å­˜ç›®å½•ï¼Œè¯·è®¾ç½® `HF_HOME` æˆ–å¯¼å‡º `HF_TOKEN`ã€‚å®Œæ•´æ¨¡å‹çº¦ 6.3GBï¼Œæ¨ç†æ—¶éœ€é¢„ç•™ ~13GB å†…å­˜ï¼ˆæ¨¡å‹ + æ¿€æ´»ï¼‰ã€‚

### é¢„æ„å»ºäº§ç‰©

ä¸æƒ³è‡ªå·±ç¼–è¯‘ï¼Ÿç‚¹è¿™é‡Œ [Github Actions](https://github.com/TimmyOVO/deepseek-ocr.rs/actions/workflows/build-binaries.yml) é‡Œäº§å‡º macOSï¼ˆå« Metalï¼‰å’Œ Windows å‹ç¼©åŒ…ã€‚ç™»å½• GitHubï¼Œæ‰“å¼€æœ€æ–°ä¸€æ¬¡ç»¿è‰²è¿è¡Œï¼Œä¸‹è½½ `deepseek-ocr-macos` æˆ– `deepseek-ocr-windows` å³å¯ã€‚

## é…ç½®ä¸ä¼˜å…ˆçº§ ğŸ—‚ï¸

CLI ä¸ Server å…±äº«åŒä¸€ä»½é…ç½®ã€‚é¦–æ¬¡å¯åŠ¨ä¼šåœ¨ç³»ç»Ÿé…ç½®ç›®å½•ç”Ÿæˆå¸¦é»˜è®¤å€¼çš„ `config.toml`ï¼Œåç»­è¿è¡Œéƒ½ä¼šæ²¿ç”¨è¯¥æ–‡ä»¶ç¡®ä¿ä¸¤ä¸ªå…¥å£ä¿æŒä¸€è‡´ã€‚

| å¹³å° | é»˜è®¤é…ç½®æ–‡ä»¶ | æ¨¡å‹ç¼“å­˜ç›®å½• |
| --- | --- | --- |
| Linux | `~/.config/deepseek-ocr/config.toml` | `~/.cache/deepseek-ocr/models/<id>/â€¦` |
| macOS | `~/Library/Application Support/deepseek-ocr/config.toml` | `~/Library/Caches/deepseek-ocr/models/<id>/â€¦` |
| Windows | `%APPDATA%\deepseek-ocr\config.toml` | `%LOCALAPPDATA%\deepseek-ocr\models\<id>\â€¦` |

- å¯é€šè¿‡ `--config /path/to/config.toml`ï¼ˆCLI/Server é€šç”¨ï¼‰è‡ªå®šä¹‰è·¯å¾„ï¼›å½“æ–‡ä»¶ä¸å­˜åœ¨æ—¶ä¼šè‡ªåŠ¨åˆ›å»ºå¹¶å†™å…¥é»˜è®¤å†…å®¹ã€‚
- é»˜è®¤çš„ `config.toml` å·²åŒ…å« `deepseek-ocr`ï¼ˆé»˜è®¤ï¼‰ä¸ `paddleocr-vl` ä¸¤ä¸ªæ¨¡å‹æ¡ç›®ï¼Œå¯é€šè¿‡ `--model paddleocr-vl`ï¼ˆæˆ–ä¿®æ”¹ `[models].active`ï¼‰åœ¨ DeepSeek ä¸ PaddleOCR-VL ä¹‹é—´å³æ—¶åˆ‡æ¢ã€‚
- éœ€è¦è‡ªå®šä¹‰èµ„æºä½ç½®æ—¶ï¼Œå¯åœ¨å¯¹åº” `models.entries.<id>` ä¸‹è®¾ç½® `config`/`tokenizer`/`weights`ï¼Œæˆ–ç›´æ¥åœ¨è¿è¡Œæ—¶ä½¿ç”¨ `--model-config`ã€`--tokenizer`ã€`--weights` è¦†ç›–ã€‚
- `config.toml` ä¸­çš„ `[models.entries."<id>"]` èŠ‚ç‚¹å…è®¸ä¸ºä¸åŒæ¨¡å‹æŒ‡å®šç‹¬ç«‹çš„ `config`ã€`tokenizer`ã€`weights` è·¯å¾„ï¼›è‹¥ç•™ç©ºåˆ™ä½¿ç”¨ä¸Šè¡¨æ‰€ç¤ºç¼“å­˜ç›®å½•å¹¶æŒ‰éœ€ä¸‹è½½ã€‚
- å‚æ•°è¦†ç›–é¡ºåºä¸ºï¼šå‘½ä»¤è¡Œå‚æ•° â†’ `config.toml` â†’ å†…ç½®é»˜è®¤å€¼ã€‚HTTP API è¯·æ±‚ä½“ä¸­çš„å­—æ®µï¼ˆä¾‹å¦‚ `max_tokens`ï¼‰ä¼šåœ¨è¯¥æ¬¡è°ƒç”¨ä¸­ç»§ç»­è¦†ç›–å‰è¿°è®¾ç½®ã€‚

é»˜è®¤é…ç½®æ–‡ä»¶å†…å®¹å¦‚ä¸‹ï¼Œå¯æ ¹æ®éœ€è¦ä¿®æ”¹åé•¿æœŸç”Ÿæ•ˆï¼š

```toml
[models]
active = "deepseek-ocr"

[models.entries.deepseek-ocr]

[inference]
device = "cpu"
template = "plain"
base_size = 1024
image_size = 640
crop_mode = true
max_new_tokens = 512
use_cache = true

[server]
host = "0.0.0.0"
port = 8000
```

- `[models]` ç”¨äºæŒ‡å®šå½“å‰æ¿€æ´»çš„æ¨¡å‹ä»¥åŠé¢å¤–çš„æ¨¡å‹æ¡ç›®ï¼ˆæ¯ä¸ªæ¡ç›®éƒ½å¯ä»¥æŒ‡å‘å„è‡ªçš„é…ç½®ã€Tokenizer ä¸æƒé‡æ–‡ä»¶ï¼‰ã€‚
- `[inference]` æä¾› CLI ä¸ Server å…±ç”¨çš„æ¨ç†é»˜è®¤å€¼ï¼ˆè®¾å¤‡ã€æ¨¡æ¿ã€è§†è§‰åˆ†è¾¨ç‡ã€ç”Ÿæˆé•¿åº¦ä¸ç¼“å­˜ç­–ç•¥ï¼‰ã€‚
- `[server]` å†³å®šç½‘ç»œç›‘å¬åœ°å€ä»¥åŠ `/v1/models` è¿”å›çš„æ¨¡å‹åã€‚

æ›´å¤šè¦†ç›–é¡¹è¯¦è§ `crates/cli/README_CN.md` ä¸ `crates/server/README_CN.md`ã€‚

## åŸºå‡†å¯¹æ¯” ğŸ“Š

ä¸‹è¡¨å±•ç¤ºåœ¨åŒä¸€å¼ å›¾åƒä¸æç¤ºè¯ä¸‹ï¼Œå¯ç”¨äº† Accelerate çš„ Rust CLIï¼ˆå•æ¬¡è¯·æ±‚ï¼‰ä¸ Python å‚è€ƒå®ç°çš„æ€§èƒ½è¡¨ç°ï¼š

| é˜¶æ®µï¼ˆStageï¼‰                                     | ref total (ms) | ref avg (ms) | python total | python/ref |
|--------------------------------------------------|----------------|--------------|--------------|------------|
| Decode â€“ Overall (`decode.generate`)             | 30077.840      | 30077.840    | 56554.873    | 1.88x      |
| Decode â€“ Token Loop (`decode.iterative`)         | 26930.216      | 26930.216    | 39227.974    | 1.46x      |
| Decode â€“ Prompt Prefill (`decode.prefill`)       | 3147.337       | 3147.337     | 5759.684     | 1.83x      |
| Prompt â€“ Build Tokens (`prompt.build_tokens`)    | 0.466          | 0.466        | 45.434       | 97.42x     |
| Prompt â€“ Render Template (`prompt.render`)       | 0.005          | 0.005        | 0.019        | 3.52x      |
| Vision â€“ Embed Images (`vision.compute_embeddings`)| 6391.435     | 6391.435     | 3953.459     | 0.62x      |
| Vision â€“ Prepare Inputs (`vision.prepare_inputs`)| 62.524         | 62.524       | 45.438       | 0.73x      |

## å‘½ä»¤è¡Œå·¥å…· ğŸ–¥ï¸

ç›´æ¥è¿è¡Œï¼š

```bash
cargo run -p deepseek-ocr-cli --release -- \
  --prompt "<image>\n<|grounding|>Convert this receipt to markdown." \
  --image baselines/sample/images/test.png \
  --device cpu --max-new-tokens 512
```

> macOS ç”¨æˆ·å¯ä»¥åœ¨ `cargo run`/`cargo build` å‘½ä»¤åé™„åŠ  `--features metal` ä»¥å¯ç”¨ Accelerate + Metal åç«¯ã€‚
>
> Linux/Windows ç”¨æˆ·ï¼šé™„åŠ  `--features cuda` å¹¶åœ¨è¿è¡Œå‚æ•°ä¸­åŠ å…¥ `--device cuda --dtype f16`ï¼Œå³å¯ä½¿ç”¨ NVIDIA GPU åŠ é€Ÿã€‚
>
> Intel MKL é¢„è§ˆï¼šå…ˆå®‰è£… Intel oneMKLï¼Œæ„å»ºæ—¶é™„åŠ  `--features mkl`ï¼Œå¯åœ¨ x86 CPU ä¸Šå–å¾—æ›´é«˜çš„çŸ©é˜µè¿ç®—æ€§èƒ½ã€‚

å®‰è£…æˆå…¨å±€äºŒè¿›åˆ¶ï¼š

```bash
cargo install --path crates/cli
deepseek-ocr-cli --help
```

å¸¸ç”¨å‚æ•°ï¼š

- `--prompt` / `--prompt-file`ï¼šåŒ…å« `<image>` å ä½ç¬¦çš„æç¤ºè¯
- `--image`ï¼šä¸ `<image>` æ•°é‡ä¸€è‡´çš„å›¾ç‰‡è·¯å¾„
- `--device` / `--dtype`ï¼šmacOS å»ºè®® `--device metal --dtype f16`ï¼ŒNVIDIA ç”¨æˆ·ä½¿ç”¨ `--device cuda --dtype f16`
- `--max-new-tokens`ï¼šç”Ÿæˆé•¿åº¦ä¸Šé™
- Sampling ç›¸å…³ï¼š`--do-sample`ã€`--temperature`ã€`--top-p`ã€`--top-k`ã€`--repetition-penalty`ã€`--no-repeat-ngram-size`ã€`--seed`
  - é»˜è®¤ä¿æŒç¡®å®šæ€§è¾“å‡ºï¼ˆ`do_sample=false`ã€`temperature=0.0`ã€`no_repeat_ngram_size=20`ï¼‰
  - è‹¥éœ€è¦éšæœº samplingï¼Œè¯·æ˜¾å¼æŒ‡å®š `--do-sample true --temperature 0.8`ï¼Œå¹¶æŒ‰éœ€è°ƒæ•´å…¶ä»–å‚æ•°

## HTTP Server â˜ï¸

å¯åŠ¨ OpenAI å…¼å®¹æœåŠ¡ï¼š

```bash
cargo run -p deepseek-ocr-server --release -- \
  --host 0.0.0.0 --port 8000 \
  --device cpu --max-new-tokens 512
```

> å¦‚æœè¦åœ¨ macOS ä¸Šå¯ç”¨ Metalï¼Œè¯·ä¸ºä»¥ä¸Šå‘½ä»¤åŠ ä¸Š `--features metal`ï¼ŒåŒæ—¶è¿è¡Œæ—¶é…åˆ `--device metal`ã€‚
>
> Intel MKL é¢„è§ˆï¼šæ„å»ºå‰å®‰è£… Intel oneMKLï¼Œå†é™„åŠ  `--features mkl`ï¼Œå³å¯åœ¨ x86 CPU ä¸Šè·å¾—æ›´å¿«çš„æ¨ç†é€Ÿåº¦ã€‚
>
> è‹¥åœ¨ Linux/Windows ä¸Šä½¿ç”¨ NVIDIA GPUï¼Œè¯·åŠ ä¸Š `--features cuda` å¹¶ä»¥ `--device cuda --dtype f16` å¯åŠ¨æœåŠ¡ã€‚

æ³¨æ„äº‹é¡¹ï¼š

- å›¾ç‰‡éœ€ä½¿ç”¨ `data:` URLï¼ˆbase64ï¼‰æˆ–å¯è®¿é—®çš„ `http(s)` é“¾æ¥ï¼Œç¦æ­¢æœ¬åœ°è·¯å¾„ã€‚
- Server å·²è‡ªåŠ¨å°†å¤šè½®å¯¹è¯æŠ˜å ä¸ºæœ€è¿‘ä¸€æ¬¡ user è½®æ¬¡ï¼Œä¿æŒå•è½® OCR ä½“éªŒã€‚
- ä¸ [Open WebUI](https://github.com/open-webui/open-webui) ç­‰ OpenAI å…¼å®¹å®¢æˆ·ç«¯å¼€ç®±å³ç”¨â€”â€”åªéœ€åœ¨å®¢æˆ·ç«¯è®¾ç½® `base_url` ä¸º `http://localhost:8000/v1` å¹¶é€‰æ‹© `deepseek-ocr` æ¨¡å‹ã€‚
- å¦‚æœéœ€è¦å¤§å›¾ä¸Šä¼ ï¼Œå¯åœ¨ Rocket é…ç½®é‡Œè°ƒé«˜ JSON/body limitã€‚

![Open WebUI è¿æ¥ deepseek-ocr.rs](./baselines/sample_1.png)

## GPU åŠ é€Ÿ âš¡

- **Metalï¼ˆmacOS 13+ & Apple Siliconï¼‰**ï¼šæ„å»ºå‘½ä»¤é™„åŠ  `--features metal`ï¼Œè¿è¡Œæ—¶ä½¿ç”¨ `--device metal --dtype f16`ã€‚
- **CUDAï¼ˆalphaï¼ŒLinux/Windows & NVIDIA GPUï¼‰**ï¼šæå‰å®‰è£… CUDA 12.2+ï¼Œæ„å»ºæ—¶åŠ  `--features cuda`ï¼Œæ‰§è¡Œæ—¶ä¼ å…¥ `--device cuda --dtype f16`ã€‚
- **Intel MKLï¼ˆé¢„è§ˆï¼‰**ï¼šå®‰è£… Intel oneMKLï¼Œæ„å»ºæ—¶é™„åŠ  `--features mkl`ï¼Œå¯æå‡ x86 CPU æ¨ç†æ€§èƒ½ã€‚
- æ— è®ºä½¿ç”¨å“ªç§ GPUï¼Œæ¨è `cargo build --release -p deepseek-ocr-cli --features metal|cuda` ä»¥è·å–æ›´é«˜ååã€‚
- ç»“åˆ `--max-new-tokens`ã€`--crop-mode` ç­‰å‚æ•°å¯åœ¨å»¶è¿Ÿä¸è´¨é‡ä¹‹é—´åšæƒè¡¡ã€‚

## Docker æ„å»ºä¸è¿è¡Œï¼ˆCUDA 12.1 + Ubuntu 22.04 + RTX 4090ï¼‰

```bash
cd /home/lxn/dev/deepseek-ocr.rs

sudo docker build \
  --build-arg CUDA_VERSION=12.1.1 \
  --build-arg UBUNTU_VERSION=22.04 \
  --build-arg CUDA_COMPUTE_CAP=89 \    # 4090
  -t deepseek-ocr-rs:cuda-12.1-ubuntu22.04 \
  -f Dockerfile .

sudo docker run -d --name deepseek-ocr --gpus all \
  -p 8000:8000 \
  --shm-size=1G \
  -v /home/lxn/dev/DeepSeek-OCR-vllm-service/models/DeepSeek-OCR:/models/deepseek-ocr \
  deepseek-ocr-rs:cuda-12.1-ubuntu22.04 \
  --model deepseek-ocr \
  --weights /models/deepseek-ocr/model-00001-of-000001.safetensors \
  --tokenizer /models/deepseek-ocr/tokenizer.json \
  --model-config /models/deepseek-ocr/config.json \
  --host 0.0.0.0 \
  --port 8000 \
  --device cuda \
  --max-new-tokens 512
```

æ³¨æ„ï¼š
- 4090 çš„ Compute Capability ä¸º 89ï¼›å¦‚éœ€å…¶ä»–æ˜¾å¡ï¼Œè¯·æ›¿æ¢ `CUDA_COMPUTE_CAP`ã€‚
- è‹¥ `CUDA_VERSION=12.1.1` æ‹‰å–å¤±è´¥ï¼Œå¯å°è¯• `12.1.0` æˆ–å¯¹åº”çš„ `-base/-devel` æ ‡ç­¾ã€‚
- è¿è¡Œæ—¶éœ€å¯ç”¨å®¿ä¸»æœºçš„ NVIDIA Container Toolkitï¼ˆæˆ– snap ç‰ˆ Docker çš„ nvidia runtimeï¼‰ï¼Œç¡®ä¿ `docker run --gpus all` å¯ç”¨ã€‚
- é•œåƒçš„ `ENTRYPOINT` å·²è®¾ä¸º `deepseek-ocr-server`ï¼Œ`docker run` æ—¶åªéœ€ä¼ å‚æ•°ï¼Œä¸è¦é‡å¤å¯æ‰§è¡Œåã€‚

## PaddleOCRâ€‘VL ä½¿ç”¨ç¤ºä¾‹ï¼ˆHTTP è¯·æ±‚ï¼‰

- åˆ‡æ¢æ¨¡å‹ï¼šå°†å¯åŠ¨å‚æ•°æˆ– HTTP è¯·æ±‚ä¸­çš„ `model` è®¾ä¸º `paddleocr-vl`ã€‚è‹¥ä¸æ˜¾å¼æŒ‡å®šæƒé‡/é…ç½®/åˆ†è¯å™¨è·¯å¾„ï¼ŒæœåŠ¡ä¼šåœ¨é¦–æ¬¡è¯·æ±‚æ—¶è‡ªåŠ¨ä¸‹è½½å¹¶ç¼“å­˜æ‰€éœ€èµ„äº§ã€‚
- èµ„æºå ç”¨æ›´ä½ã€å¯åŠ¨æ›´å¿«ï¼Œé€‚åˆè½»é‡éƒ¨ç½²ä¸æ‰¹å¤„ç†åœºæ™¯ã€‚

å¯åŠ¨æœåŠ¡ï¼ˆDocker ç¤ºä¾‹ï¼Œä½¿ç”¨ GPUï¼Œè‡ªåŠ¨ä¸‹è½½æ¨¡å‹èµ„äº§ï¼‰ï¼š
```bash
sudo docker run -d --name paddleocr-vl --gpus all \
  -p 8001:8000 \
  --shm-size=1G \
  deepseek-ocr-rs:cuda-12.1-ubuntu22.04 \
  --model paddleocr-vl \
  --host 0.0.0.0 \
  --port 8000 \
  --device cuda \
  --max-new-tokens 512
```

HTTP è¯·æ±‚ï¼ˆOpenAI å…¼å®¹ `/v1/chat/completions`ï¼‰ï¼š
```bash
# å°†å›¾ç‰‡è½¬æˆ data URLï¼ˆç¤ºä¾‹ï¼‰
b64=$(base64 -w0 sample.png)
echo "data:image/png;base64,$b64" > img.dataurl

# å‘é€è¯·æ±‚
curl -X POST http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "paddleocr-vl",
    "max_tokens": 512,
    "messages": [
      {
        "role": "user",
        "content": [
          { "type": "text", "text": "è¯·å°†å›¾ç‰‡å†…å®¹è½¬ä¸ºç»“æ„åŒ– Markdownã€‚" },
          { "type": "image_url", "image_url": { "url": "'"$(cat img.dataurl)"'" } }
        ]
      }
    ]
  }'
```

å¯é€‰ï¼šä½¿ç”¨ `/v1/responses` è·¯ç”±
```bash
curl -X POST http://localhost:8000/v1/responses \
  -H "Content-Type: application/json" \
  -d '{
    "model": "paddleocr-vl",
    "max_output_tokens": 512,
    "input": [
      {
        "role": "user",
        "content": [
          { "type": "input_text", "text": "å°†å›¾ç‰‡è½¬æ¢ä¸º Markdownã€‚" },
          { "type": "input_image", "image_url": "'"$(cat img.dataurl)"'" }
        ]
      }
    ]
  }'
```

æ³¨æ„ï¼š
- å¤šé¡µ PDF è¯·å…ˆè½¬æˆå¤šå¼ å›¾ç‰‡ï¼Œç„¶ååœ¨åŒä¸€æ¡æ¶ˆæ¯ä¸­ä¼ å¤šä¸ª image æ®µï¼›æˆ–åˆ†æ‰¹è¯·æ±‚ååœ¨å®¢æˆ·ç«¯åˆå¹¶ã€‚
- è‹¥å“åº”è¢«æˆªæ–­ï¼Œè°ƒå¤§ `max_tokens`/`max_output_tokens`ï¼›è‹¥è¯·æ±‚ä½“è¿‡å¤§ï¼Œå¯é™ä½å›¾ç‰‡åˆ†è¾¨ç‡æˆ–åˆ†æ‰¹ä¸Šä¼ ã€‚

## ç›®å½•ç»“æ„ ğŸ—‚ï¸

- `crates/core`ï¼šæ¨ç†ç®¡çº¿ã€æ¨¡å‹è£…è½½ã€ä¼šè¯æ¨¡æ¿ã€‚
- `crates/cli`ï¼šå‘½ä»¤è¡Œå…¥å£ `deepseek-ocr-cli`ã€‚
- `crates/server`ï¼šæä¾› OpenAI é£æ ¼ API çš„ Rocket æœåŠ¡ã€‚
- `crates/assets`ï¼šæ¨¡å‹/Tokenizer ä¸‹è½½ä¸ç¼“å­˜å·¥å…·ã€‚
- `baselines/`ï¼šåŸºå‡†è¾“å…¥è¾“å‡ºæ ·ä¾‹ï¼Œä¾¿äºå›å½’æµ‹è¯•ã€‚

æ›´å¤š CLI è¯´æ˜è¯·å‚è§ [`crates/cli/README_CN.md`](crates/cli/README_CN.md)ï¼›æœåŠ¡ç«¯ API è¯¦è§ [`crates/server/README_CN.md`](crates/server/README_CN.md)ã€‚

## å¸¸è§é—®é¢˜ ğŸ› ï¸

- **èµ„äº§ä¸‹è½½æº**ï¼šä¼šè‡ªåŠ¨åœ¨ Hugging Face ä¸ ModelScope ä¹‹é—´æŒ‰å»¶è¿Ÿæ‹©ä¼˜ã€‚å‘½ä»¤è¡Œä¼šæç¤ºå½“å‰ä½¿ç”¨çš„æºä¸ç›®æ ‡è·¯å¾„ã€‚
- **ä¸‹è½½å¤±è´¥**ï¼šç¡®è®¤ `HF_TOKEN` å·²é…ç½®ï¼Œæˆ–é‡è¯•ä»¥åˆ©ç”¨ Hugging Face/ModelScope ç¼“å­˜ã€‚
- **é¦–è½®è€—æ—¶é•¿**ï¼šç¬¬ä¸€æ¬¡æ¨ç†éœ€è¦åŠ è½½æ¨¡å‹å¹¶çƒ­å¯åŠ¨ GPUï¼ˆMetal/CUDA Î±)ï¼Œåç»­ä¼šæ›´å¿«ã€‚
- **å›¾ç‰‡è¿‡å¤§è¢«æ‹’**ï¼šæ”¾å¤§ Rocket é™é¢æˆ–å¯¹å›¾åƒè¿›è¡Œä¸‹é‡‡æ ·ã€‚

## è‡´è°¢ ğŸ™

- æ¨¡å‹ç”± [DeepSeek-AI](https://huggingface.co/deepseek-ai/DeepSeek-OCR) æä¾›ã€‚
- é¡¹ç›®ä¾èµ– Candleã€Rocket ç­‰ä¼˜ç§€ Rust å¼€æºç”Ÿæ€ï¼Œæ„Ÿè°¢æ‰€æœ‰ç»´æŠ¤è€…ã€‚

## è®¸å¯è¯ ğŸ“„

æœ¬ä»“åº“éµå¾ªä¸Šæ¸¸ DeepSeek-OCR æ¨¡å‹çš„ä½¿ç”¨æ¡æ¬¾ï¼Œè¯¦è§ `DeepSeek-OCR/LICENSE`ï¼Œä¸‹æ¸¸ä½¿ç”¨è¯·éµå®ˆç›¸åŒé™åˆ¶ã€‚
